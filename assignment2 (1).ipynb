{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Noisy channel models and the Viterbi algorithm\n",
    "\n",
    "## Due: by 11:59pm, Sunday 11/03\n",
    "\n",
    "*Note: late submissions are accepted up to 5 days after the deadline for this assignment. You will receive 4 free late days over the course; once you exhaust those late days, each (partial) day that a submission is late will cap your maximum grade for the assignment by 5%. If you submit this assignment more than 5 days late, you will receive no credit.*\n",
    "\n",
    "**Before submitting**, please click the *Kernel* menu at the top of JupyterLab and select the *Restart Kernel and Run All Cells...* button, then click the red *Restart* button on the box that pops up. This ensures that your code will run on its own, without relying on information that you may have added and then removed when developing it.\n",
    "\n",
    "**To submit** your assignment, first make sure you have saved it, by pressing *Ctrl + S* or *Cmd + S* or clicking on the disk icon at the top of the notebook. Then enter the command `submit_assignment 2` in the *Terminal*. You can submit as many times as you like, without penalty. If you'd like to discuss something from your assignment with us (e.g. in office hours), please submit it first, so that we can easily see what you've been working on.\n",
    "\n",
    "When you submit, a message will appear asking you if you want to mark the submission as FINAL. **You need to mark the submission as FINAL in order to have it graded.** After marking your submission as FINAL, you will no longer be able to re-submit. This is so that we can accurately track the date of your final submission with respect to the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please answer these questions prior to submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Did you consult anyone other than the instructor, or any resources other than those listed on Canvas, for this assignment? If so, please list them below.**</span>\n",
    "\n",
    "> It is fine to consult classmates and external resources, as long as the work you submit is your own. I would just like to know who you consulted, or what other resources you might have found helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I discussed with yanlu about the part 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**For Part 3, have you chosen to complete option A (real-world effects) or option B (applications to language-based research)?**</span>\n",
    "\n",
    "> Remember, you can only choose each option *twice* over the four assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**For which part of the assignment would you like to receive double points?**</span>\n",
    "\n",
    "> You can choose Part 1, 2, or 3, and you can choose the same or different parts across assignments with no restrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Autocorrect with Noisy Channel modeling [25 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment, you will use a provided codebase to explore the influence of various components of the noisy channel spelling model. *Note: the codebase is written for exploratory purposes, not for efficiency. It would not be a good tool to use for any large-scale practical tasks!*\n",
    "\n",
    "**You must run the code cells below in order to be able to use the autocorrect tools in the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arpa\n",
    "from util import run_srilm, ErrorModel, CandidateGenerator, SpellCorrector\n",
    "import math\n",
    "import pandas as pd \n",
    "\n",
    "simple_candidate_gen = CandidateGenerator(1, \"inputs/words.txt\")\n",
    "uniform_error_model = ErrorModel(\"inputs/errors_uniform.txt\")\n",
    "uniform_language_model = arpa.loadf(\"models/uniform.lm\")[0]\n",
    "simple_corrector = SpellCorrector(simple_candidate_gen, uniform_error_model, uniform_language_model, noerror_rate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The spelling corrector\n",
    "\n",
    "The codebase for this assignment provides you with a `SpellCorrector` object, which combines a candidate generator, an error model, and a language model, in order to perform spelling correction.\n",
    "\n",
    "One of the primary methods of the spelling corrector is `SpellCorrector.correct_word()`, which evaluates candidates for correcting a single word in a sentence. The method takes two arguments: a string representing a sentence, and an integer representing the index of the word in the sentence that is to be corrected (as in all things Python, the first word is indexed by the number 0). It returns a DataFrame containing information about each candidate, including its scores (log-probabilities) on the error model and language model separately and together. The candidates (rows) in the DataFrame are sorted so that the best candidate appears at the top.\n",
    "\n",
    "The code cell below demonstrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>candidate</th>\n",
       "      <th>distance</th>\n",
       "      <th>position</th>\n",
       "      <th>sentence</th>\n",
       "      <th>error_score</th>\n",
       "      <th>lm_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hlelo</td>\n",
       "      <td>hello</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hello world</td>\n",
       "      <td>-2.460898</td>\n",
       "      <td>-11.80618</td>\n",
       "      <td>-14.267078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target candidate  distance  position     sentence  error_score  lm_score  \\\n",
       "0  hlelo     hello         1         0  hello world    -2.460898 -11.80618   \n",
       "\n",
       "       score  \n",
       "0 -14.267078  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_corrector.correct_word(\"hlelo world\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All noisy channel models rest upon assumptions about the noise process, i.e. the way that a signal may get distorted. For the present simple spelling corrector, when an error is considered -- say, the non-word *acress* -- it is assumed that it derives from an intended real word by means of a single letter-change (i.e. insertion, *acres* > *acress*; deletion, *actress* > *acress*; substitution, *access* > *acress*; or transposition, *caress* > *acress*). We treat each change as targeting a part of the word that consists of two letters (i.e., a bigraph): for insertion, an extra letter is inserted in the middle of the bigraph part (*es* > *e**s**s*); for deletion, the second letter of the bigraph part is removed (*c**t*** > *c*); for substitution, the first letter of the bigraph part is swapped with something else (*ce* > ***r**e*); and for transposition, the order of the two letters in the bigraph part is swapped (*ca* > ***ac***). \n",
    "\n",
    "The error model assumes that a change to an intended word is sampled from the set of valid changes that can be applied across all bigraph parts in that word, through two steps: first, a part is picked; and second, a change is applied to that part. Together, these two steps yield a probability distribution over changes that could have been applied to the intended word (i.e. a joint probability distribution over the bigraph part and result of a change).  \n",
    "> For the purposes of this assignment, we assume that a part is sampled in proportion to the total number of times we have seen any change applied to that part (in any word), based on a corpus of spelling errors. This is a little different to what we saw in the introductory lecture, where parts were sampled uniformly (i.e., each with equal probability).\n",
    "\n",
    "It is very important to understand that **the changes are based on the intended real word, not the observed non-word**; for example, the error model probability for the candidate *actress* as a correction of *acress* is based on considering the change that transforms *actress* into *acress* against the backdrop of all other changes that could have applied to *actress*, rather than on considering the change that transforms *acress* into *actress* against the backdrop of all other changes that could have transformed *acress* into a real word. In this way, the error model represents a form of reverse-engineering how an observed non-word could have derived from a real word, if that real word were the intended word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1: Candidate generation [10 points]\n",
    "\n",
    "When faced with a non-word, the first task is to find candidate real-word corrections for it.\n",
    "\n",
    "The codebase for this assignment provides you with a `CandidateGenerator` that can perform this task. The generator finds all candidate real-words that can be obtained within a provided number of letter-changes from a target non-word.\n",
    "\n",
    "In the setup for this Notebook, you created a simple candidate generator via\n",
    "```python\n",
    "simple_candidate_gen = CandidateGenerator(1, \"inputs/words.txt\")\n",
    "```\n",
    "\n",
    "The first argument (`1`) is the maximum number of letter-changes to apply. The second argument (`inputs/words.txt`) is the path to a text file containing real words, which is used to filter the generated candidates.\n",
    "\n",
    "You can use a generator to generate candidate corrections for a target with the `CandidateGenerator.candidates()` method. This method takes the target as an argument, as in `simple_candidate_gen.candidates(\"yse\")`, and produces a DataFrame containing the candidate real word corrections for that target.\n",
    "\n",
    "Run the code cell below to generate candidates for the non-word `ot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>distance</th>\n",
       "      <th>paths_to_target</th>\n",
       "      <th>paths_from_candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>et</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ut</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>op</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>or</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ox</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>oz</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>got</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>wot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>oat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>oft</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>opt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>out</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   candidate  distance  paths_to_target  paths_from_candidate\n",
       "0          t         1                1                    78\n",
       "1          o         1                1                    78\n",
       "2         to         1                1                   131\n",
       "3         at         1                1                   131\n",
       "4         et         1                1                   131\n",
       "5         it         1                1                   131\n",
       "6         ut         1                1                   131\n",
       "7         of         1                1                   131\n",
       "8         oh         1                1                   131\n",
       "9         oi         1                1                   131\n",
       "10        on         1                1                   131\n",
       "11        op         1                1                   131\n",
       "12        or         1                1                   131\n",
       "13        ow         1                1                   131\n",
       "14        ox         1                1                   131\n",
       "15        oz         1                1                   131\n",
       "16       cot         1                1                   184\n",
       "17       dot         1                1                   184\n",
       "18       got         1                1                   184\n",
       "19       hot         1                1                   184\n",
       "20       jot         1                1                   184\n",
       "21       lot         1                1                   184\n",
       "22       mot         1                1                   184\n",
       "23       not         1                1                   184\n",
       "24       pot         1                1                   184\n",
       "25       rot         1                1                   184\n",
       "26       sot         1                1                   184\n",
       "27       tot         1                1                   184\n",
       "28       wot         1                1                   184\n",
       "29       oat         1                1                   184\n",
       "30       oft         1                1                   184\n",
       "31       opt         1                1                   184\n",
       "32       out         1                1                   184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_candidate_gen.candidates(\"ot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output DataFrame contains the candidates in the first column, the distance in number of letter-changes between the target and candidate in the second column, and other information in other columns. Soon, you'll explore what this other information means. But first, think about the number of candidates that are generated, i.e. the number of rows in the DataFrame.\n",
    "\n",
    "1. Generate candidates for the non-word `hippopotamsu`. How does the number of candidates compare to the number for `ot`? Why do you think this is? **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>distance</th>\n",
       "      <th>paths_to_target</th>\n",
       "      <th>paths_from_candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hippopotamus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      candidate  distance  paths_to_target  paths_from_candidate\n",
       "0  hippopotamus         1                1                   660"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_candidate_gen.candidates(\"hippopotamsu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of candidates generated for the non-word \"hippopotamsu\" is much lower than for \"ot.\" Specifically, \"ot\" generated 33 candidates, while \"hippopotamsu\" generated only 1 candidate. This difference occurs because \"hippopotamsu\" is much longer and more specific, with fewer plausible one-letter changes that transform it into a valid real word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**paths_from_candidate**\n",
    "\n",
    "Since the noisy channel model works by reverse-engineering changes that might have transformed a candidate word into the target non-word, a candidate's evaluation by an error model will be affected by the *other* changes that might have transformed it into something *other* than the target word; in other words, by other paths that the changes could have taken the candidate along. The `paths_from_candidate` column reports on the total number of paths that changes could have taken a candidate along. For example, there are 131 total paths away from the word `to`; one of these paths leads to the target `ot` (by transposing the letters), but there are also many others, such as a path to `do` (by substituting the t with a d) and a path to `top` (by inserting a p after the o).\n",
    "\n",
    "The `paths_from_candidate` numbers come from adding together the number of possible changes that could be applied to each bigraph part in the word. The number of changes a bigraph part permits is the sum of the following:\n",
    "* 26 possible insertion changes, one for each letter that could be inserted  \n",
    "* 1 possible deletion change that targets the second letter, **except** when that letter is the end-of-word marker `#`, which cannot be deleted  \n",
    "* 25 possible substitution changes, one for each *other* identity the first letter could take, **except** when that letter is the start-of-word marker `>`, which cannot be substituted for anything else\n",
    "* 1 possible transposition change that swaps the order of the two letters, **except** when one of them is the start-of-word marker `>` or end-of-word marker `#`, which cannot be reordered, **or** when the two letters are identical, in which case reordering them does not actually change the word  \n",
    "\n",
    "For example, the word *pool* contains the following bigraph parts, each of which permits the corresponding number of valid changes:  \n",
    "* `>p`: 26 insertion + 1 deletion + 0 substitution + 0 transposition = 27 valid changes\n",
    "* `po`: 26 insertion + 1 deletion + 25 substitution + 1 transposition = 53 valid changes\n",
    "* `oo`: 26 insertion + 1 deletion + 25 substitution + 0 transposition = 52 valid changes\n",
    "* `ol`: 26 insertion + 1 deletion + 25 substitution + 1 transposition = 53 valid changes\n",
    "* `l#`: 26 insertion + 0 deletion + 25 substitution + 0 transposition = 51 valid changes\n",
    "\n",
    "This yields a total of 27 + 53 + 52 + 53 + 51 = 236 valid paths away from the real word *pool*. Each path is the result of applying a single change to a single bigraph part; therefore, each path leads to a sequence of characters that is one letter-change away from *pool*. Some paths will lead to real words and some paths will lead to non-words; some paths might even lead to the same result, obtained through different means (e.g., there are two paths that lead from *pool* to *pol*, one that deletes the first *o* and one that deletes the second *o*).\n",
    "\n",
    "Candidates can have different numbers of paths, depending on the kinds of changes that are applicable to the candidate.\n",
    "\n",
    "2. Identify the pattern in the `paths_from_candidate` column for the DataFrame for `ot` generated above. What do you think is the major factor behind that pattern? **[1 point]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern in the paths_from_candidate column for the DataFrame generated for \"ot\" shows that shorter candidates (like single letters \"t\" or \"o\") generally have fewer paths, while longer candidates (such as \"cot,\" \"dot,\" \"got\") have more paths. Longer words have more bigraph parts, and each bigraph permits a certain number of valid changes. Consequently, as the word length increases, there are more possible insertion, deletion, substitution, and transposition changes across the different bigraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**paths_to_target**\n",
    "\n",
    "When we evaluate a candidate with an error model, we need to consider all of the ways that changes could transform it into the target. The `paths_to_target` column counts how many ways there are to transform the candidate into the target, within the designated number of changes.\n",
    "\n",
    "3. Generate candidates for the non-word `acress`. What is different about the `paths_to_target` value for the candidate `acres`? Why do you think that is? **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>distance</th>\n",
       "      <th>paths_to_target</th>\n",
       "      <th>paths_from_candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cress</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acres</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caress</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>access</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>across</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actress</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  candidate  distance  paths_to_target  paths_from_candidate\n",
       "0     cress         1                1                   289\n",
       "1     acres         1                2                   290\n",
       "2    caress         1                1                   342\n",
       "3    access         1                1                   341\n",
       "4    across         1                1                   342\n",
       "5   actress         1                1                   395"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_candidate_gen.candidates(\"acress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths_to_target value for the candidate \"acres\" is different because it is 2, whereas all other candidates have a value of 1. This indicates that there are two different ways to transform \"acres\" into the non-word \"acress,\" which might be associated with the position of inserting 's'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence on spelling correction**\n",
    "\n",
    "The candidate generator has an influence on the whole spelling correction system. This can easily be seen in the simple spelling corrector we have set up, in which the error model treats all changes as equally likely, and the language model treats all words as equally likely. \n",
    "\n",
    "The idea that the error model treats all changes as equally likely can be thought of as equivalent to having observed each possible change from each possible bigraph once in a corpus of errors. Since our spelling corrector assumes that the probability of picking a bigraph part in a word as the target of a change is proportional to the number of times we have seen changes to that bigraph (in any word) in the corpus, using an error model in which all changes are equally likely means that the probability of picking a part is proportional to the number of valid changes that part permits. For example, in the case of *pool* described above, the probability of picking the part `>p` is given by 27/236, since there are 27 valid changes that can be applied to `>p` out of 236 valid changes total that can be applied to the word. Since each of the 27 changes that can be applied to this part are given equal probability, each pathway that results from applying one of them gets 1/27 of this probability mass, for a total probability of 1/236. \n",
    "\n",
    "As a consequence of using this error model and language model, any differences you observe between scores of candidates are based entirely on the `paths_from_candidate` and `paths_to_target` values.\n",
    "\n",
    "The spelling corrector can be used to correct a single target non-word via\n",
    "```python\n",
    "simple_corrector.correct_word(target_nonword, 0)\n",
    "```\n",
    "where `target_nonword` should be replaced with a string representing the target non-word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generate corrections for the non-word `ot`. Why are the best candidates best? What does this tell you about how candidate generation can affect spelling correction? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>candidate</th>\n",
       "      <th>distance</th>\n",
       "      <th>error_score</th>\n",
       "      <th>lm_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ot</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.892095</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.096215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ot</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.892095</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.096215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ot</td>\n",
       "      <td>oi</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ot</td>\n",
       "      <td>oz</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ot</td>\n",
       "      <td>ox</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ot</td>\n",
       "      <td>ow</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ot</td>\n",
       "      <td>op</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ot</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ot</td>\n",
       "      <td>or</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ot</td>\n",
       "      <td>oh</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ot</td>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ot</td>\n",
       "      <td>ut</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ot</td>\n",
       "      <td>it</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ot</td>\n",
       "      <td>et</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ot</td>\n",
       "      <td>at</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ot</td>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.117271</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.321391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ot</td>\n",
       "      <td>pot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ot</td>\n",
       "      <td>opt</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ot</td>\n",
       "      <td>oft</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ot</td>\n",
       "      <td>oat</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ot</td>\n",
       "      <td>wot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ot</td>\n",
       "      <td>tot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ot</td>\n",
       "      <td>sot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ot</td>\n",
       "      <td>rot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ot</td>\n",
       "      <td>cot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ot</td>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ot</td>\n",
       "      <td>mot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ot</td>\n",
       "      <td>lot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ot</td>\n",
       "      <td>jot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ot</td>\n",
       "      <td>hot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ot</td>\n",
       "      <td>got</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ot</td>\n",
       "      <td>dot</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ot</td>\n",
       "      <td>out</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.264818</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.468938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target candidate  distance  error_score  lm_score     score\n",
       "0      ot         t         1    -1.892095  -1.20412 -3.096215\n",
       "1      ot         o         1    -1.892095  -1.20412 -3.096215\n",
       "2      ot        oi         1    -2.117271  -1.20412 -3.321391\n",
       "3      ot        oz         1    -2.117271  -1.20412 -3.321391\n",
       "4      ot        ox         1    -2.117271  -1.20412 -3.321391\n",
       "5      ot        ow         1    -2.117271  -1.20412 -3.321391\n",
       "6      ot        op         1    -2.117271  -1.20412 -3.321391\n",
       "7      ot        on         1    -2.117271  -1.20412 -3.321391\n",
       "8      ot        or         1    -2.117271  -1.20412 -3.321391\n",
       "9      ot        oh         1    -2.117271  -1.20412 -3.321391\n",
       "10     ot        of         1    -2.117271  -1.20412 -3.321391\n",
       "11     ot        ut         1    -2.117271  -1.20412 -3.321391\n",
       "12     ot        it         1    -2.117271  -1.20412 -3.321391\n",
       "13     ot        et         1    -2.117271  -1.20412 -3.321391\n",
       "14     ot        at         1    -2.117271  -1.20412 -3.321391\n",
       "15     ot        to         1    -2.117271  -1.20412 -3.321391\n",
       "16     ot       pot         1    -2.264818  -1.20412 -3.468938\n",
       "17     ot       opt         1    -2.264818  -1.20412 -3.468938\n",
       "18     ot       oft         1    -2.264818  -1.20412 -3.468938\n",
       "19     ot       oat         1    -2.264818  -1.20412 -3.468938\n",
       "20     ot       wot         1    -2.264818  -1.20412 -3.468938\n",
       "21     ot       tot         1    -2.264818  -1.20412 -3.468938\n",
       "22     ot       sot         1    -2.264818  -1.20412 -3.468938\n",
       "23     ot       rot         1    -2.264818  -1.20412 -3.468938\n",
       "24     ot       cot         1    -2.264818  -1.20412 -3.468938\n",
       "25     ot       not         1    -2.264818  -1.20412 -3.468938\n",
       "26     ot       mot         1    -2.264818  -1.20412 -3.468938\n",
       "27     ot       lot         1    -2.264818  -1.20412 -3.468938\n",
       "28     ot       jot         1    -2.264818  -1.20412 -3.468938\n",
       "29     ot       hot         1    -2.264818  -1.20412 -3.468938\n",
       "30     ot       got         1    -2.264818  -1.20412 -3.468938\n",
       "31     ot       dot         1    -2.264818  -1.20412 -3.468938\n",
       "32     ot       out         1    -2.264818  -1.20412 -3.468938"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_corrector.correct_word(\"ot\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best candidates for the non-word \"ot\" are \"t\" and \"o,\" both of which have the highest scores (less negative) of -3.096215. These candidates have a better score because they have higher paths_to_target values and relatively fewer paths_from_candidate values compared to other candidates. This indicates that candidates with fewer paths away from them are more likely to be selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Generate corrections for the non-word `acress`. Compare the scores for `acres` and `cress`. Which one is better, and why? What does this tell you about how candidate generation can affect spelling correction? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>candidate</th>\n",
       "      <th>distance</th>\n",
       "      <th>error_score</th>\n",
       "      <th>lm_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acress</td>\n",
       "      <td>acres</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.161368</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.365488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acress</td>\n",
       "      <td>cress</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.460898</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.665018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acress</td>\n",
       "      <td>access</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.532754</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.736874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acress</td>\n",
       "      <td>caress</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.534026</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.738146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acress</td>\n",
       "      <td>across</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.534026</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.738146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acress</td>\n",
       "      <td>actress</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.596597</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.800717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target candidate  distance  error_score  lm_score     score\n",
       "0  acress     acres         1    -2.161368  -1.20412 -3.365488\n",
       "1  acress     cress         1    -2.460898  -1.20412 -3.665018\n",
       "2  acress    access         1    -2.532754  -1.20412 -3.736874\n",
       "3  acress    caress         1    -2.534026  -1.20412 -3.738146\n",
       "4  acress    across         1    -2.534026  -1.20412 -3.738146\n",
       "5  acress   actress         1    -2.596597  -1.20412 -3.800717"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_corrector.correct_word(\"acress\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The candidate \"acres\" has a better score (-3.365488) compared to \"cress\" (-3.665018). The reason \"acres\" is ranked higher is due to its higher paths_to_target value and a relatively lower paths_from_candidate value compared to \"cress.\" This comparison highlights that the system prioritizes candidates that can be reached through more error pathways (higher paths_to_target), which increases their likelihood under the error model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Candidate generation beyond 1 change**\n",
    "\n",
    "The code cell below creates a spelling corrector in which the candidate generator is allowed to generate candidates that are 1 or 2 letter-changes away from the target non-word. This means that more candidates are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twochange_candidate_gen = CandidateGenerator(2, \"inputs/words.txt\")\n",
    "twochange_corrector = SpellCorrector(twochange_candidate_gen, uniform_error_model, uniform_language_model, noerror_rate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use this new spelling corrector to generate corrections for `acress`, as before. What do you notice about the error model scores for the new candidates? Why do you think this is, and what does it tell you about how candidate generation can affect spelling correction? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>candidate</th>\n",
       "      <th>distance</th>\n",
       "      <th>error_score</th>\n",
       "      <th>lm_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acress</td>\n",
       "      <td>acres</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.240549</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.444669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acress</td>\n",
       "      <td>cress</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.540079</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.744199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acress</td>\n",
       "      <td>access</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.611936</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.816056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acress</td>\n",
       "      <td>caress</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.613207</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.817327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acress</td>\n",
       "      <td>across</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.613207</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.817327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acress</td>\n",
       "      <td>actress</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.675778</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-3.879898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acress</td>\n",
       "      <td>acers</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.924796</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.128916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acress</td>\n",
       "      <td>aces</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.925588</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.129708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acress</td>\n",
       "      <td>ares</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.925588</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.129708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acress</td>\n",
       "      <td>press</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.097887</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.302007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acress</td>\n",
       "      <td>dress</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.097887</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.302007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acress</td>\n",
       "      <td>tress</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.097887</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.302007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acress</td>\n",
       "      <td>acmes</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.100887</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.305007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>acress</td>\n",
       "      <td>aches</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.100887</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.305007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>acress</td>\n",
       "      <td>ayres</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.100887</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.305007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>acress</td>\n",
       "      <td>aires</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.100887</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.305007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>acress</td>\n",
       "      <td>cares</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.100887</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.305007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acress</td>\n",
       "      <td>cess</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.222945</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.427065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>acress</td>\n",
       "      <td>acre</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.226618</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.430738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>acress</td>\n",
       "      <td>aggress</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.367084</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.571204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>acress</td>\n",
       "      <td>address</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.367084</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.571204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acress</td>\n",
       "      <td>cross</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.398917</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.603037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>acress</td>\n",
       "      <td>crass</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.398917</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.603037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>acress</td>\n",
       "      <td>chess</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.398917</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.603037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>acress</td>\n",
       "      <td>areas</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.401917</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.606037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>acress</td>\n",
       "      <td>arses</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.401917</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.606037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>acress</td>\n",
       "      <td>crest</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.401917</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.606037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>acress</td>\n",
       "      <td>crews</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.401917</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.606037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>acress</td>\n",
       "      <td>abbess</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.542630</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.746750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>acress</td>\n",
       "      <td>assess</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.542630</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.746750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>acress</td>\n",
       "      <td>duress</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.545173</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.749293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>acress</td>\n",
       "      <td>egress</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.545173</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.749293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>acress</td>\n",
       "      <td>stress</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.545173</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.749293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>acress</td>\n",
       "      <td>screes</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.545173</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.749293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>acress</td>\n",
       "      <td>agrees</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.545173</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.749293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>acress</td>\n",
       "      <td>cressy</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.545173</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.749293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>acress</td>\n",
       "      <td>arrest</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.545173</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.749293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>acress</td>\n",
       "      <td>ogress</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.545173</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.749293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>acress</td>\n",
       "      <td>carets</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.547709</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.751829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>acress</td>\n",
       "      <td>screws</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.547709</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.751829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>acress</td>\n",
       "      <td>carers</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.547709</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.751829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>acress</td>\n",
       "      <td>crests</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.547709</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.751829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>acress</td>\n",
       "      <td>afresh</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.547709</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.751829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>acress</td>\n",
       "      <td>airless</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.670315</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.874435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>acress</td>\n",
       "      <td>arrests</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.670315</td>\n",
       "      <td>-1.20412</td>\n",
       "      <td>-6.874435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target candidate  distance  error_score  lm_score     score\n",
       "0   acress     acres         1    -2.240549  -1.20412 -3.444669\n",
       "1   acress     cress         1    -2.540079  -1.20412 -3.744199\n",
       "2   acress    access         1    -2.611936  -1.20412 -3.816056\n",
       "3   acress    caress         1    -2.613207  -1.20412 -3.817327\n",
       "4   acress    across         1    -2.613207  -1.20412 -3.817327\n",
       "5   acress   actress         1    -2.675778  -1.20412 -3.879898\n",
       "6   acress     acers         2    -4.924796  -1.20412 -6.128916\n",
       "7   acress      aces         2    -4.925588  -1.20412 -6.129708\n",
       "8   acress      ares         2    -4.925588  -1.20412 -6.129708\n",
       "9   acress     press         2    -5.097887  -1.20412 -6.302007\n",
       "10  acress     dress         2    -5.097887  -1.20412 -6.302007\n",
       "11  acress     tress         2    -5.097887  -1.20412 -6.302007\n",
       "12  acress     acmes         2    -5.100887  -1.20412 -6.305007\n",
       "13  acress     aches         2    -5.100887  -1.20412 -6.305007\n",
       "14  acress     ayres         2    -5.100887  -1.20412 -6.305007\n",
       "15  acress     aires         2    -5.100887  -1.20412 -6.305007\n",
       "16  acress     cares         2    -5.100887  -1.20412 -6.305007\n",
       "17  acress      cess         2    -5.222945  -1.20412 -6.427065\n",
       "18  acress      acre         2    -5.226618  -1.20412 -6.430738\n",
       "19  acress   aggress         2    -5.367084  -1.20412 -6.571204\n",
       "20  acress   address         2    -5.367084  -1.20412 -6.571204\n",
       "21  acress     cross         2    -5.398917  -1.20412 -6.603037\n",
       "22  acress     crass         2    -5.398917  -1.20412 -6.603037\n",
       "23  acress     chess         2    -5.398917  -1.20412 -6.603037\n",
       "24  acress     areas         2    -5.401917  -1.20412 -6.606037\n",
       "25  acress     arses         2    -5.401917  -1.20412 -6.606037\n",
       "26  acress     crest         2    -5.401917  -1.20412 -6.606037\n",
       "27  acress     crews         2    -5.401917  -1.20412 -6.606037\n",
       "28  acress    abbess         2    -5.542630  -1.20412 -6.746750\n",
       "29  acress    assess         2    -5.542630  -1.20412 -6.746750\n",
       "30  acress    duress         2    -5.545173  -1.20412 -6.749293\n",
       "31  acress    egress         2    -5.545173  -1.20412 -6.749293\n",
       "32  acress    stress         2    -5.545173  -1.20412 -6.749293\n",
       "33  acress    screes         2    -5.545173  -1.20412 -6.749293\n",
       "34  acress    agrees         2    -5.545173  -1.20412 -6.749293\n",
       "35  acress    cressy         2    -5.545173  -1.20412 -6.749293\n",
       "36  acress    arrest         2    -5.545173  -1.20412 -6.749293\n",
       "37  acress    ogress         2    -5.545173  -1.20412 -6.749293\n",
       "38  acress    carets         2    -5.547709  -1.20412 -6.751829\n",
       "39  acress    screws         2    -5.547709  -1.20412 -6.751829\n",
       "40  acress    carers         2    -5.547709  -1.20412 -6.751829\n",
       "41  acress    crests         2    -5.547709  -1.20412 -6.751829\n",
       "42  acress    afresh         2    -5.547709  -1.20412 -6.751829\n",
       "43  acress   airless         2    -5.670315  -1.20412 -6.874435\n",
       "44  acress   arrests         2    -5.670315  -1.20412 -6.874435"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twochange_corrector.correct_word(\"acress\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error model scores for candidates such as \"acres\" and \"cress\" are slightly less negative compared to the earlier results produced by simple_corrector. This shift in error model scores occurs because the twochange_corrector allows for generating corrections that require two edits, thus expanding the set of potential candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Given the observation you just made, under what circumstances do you think a candidate that is more than 1 letter-change away from a target might be chosen as the best correction for a non-word, over candidates that are only 1 letter-change away? **[1 point]**\n",
    "   \n",
    "   *Hint: remember that the error model is not the only component of the spelling corrector!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can happen if the two-change candidate forms a more common or contextually appropriate word compared to the one-change candidates. The higher likelihood of the word in natural language use can outweigh the penalty from the greater edit distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: the error model [4 points]\n",
    "\n",
    "Each candidate needs to be evaluated according to how likely it is to have been transformed into the target via spelling errors. For this, we use an error model.\n",
    "\n",
    "The codebase for this assignment provides you with an `ErrorModel` that can be used to create an error model. The model is based on counts of how often various possible insertion, deletion, substitution, and transposition changes occurred in a particular dataset. The simple spelling corrector we used before contained an error model trained on a *uniform* dataset that assumes all changes could occur equally often. Here, we will explore an error model trained on a dataset of actual change occurrences, provided by Peter Norvig.\n",
    "\n",
    "The code cell below creates the new error model, and a new spelling corrector that incorporates it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_model = ErrorModel(\"inputs/errors_corpus.txt\")\n",
    "candidate_gen = CandidateGenerator(1, \"inputs/words.txt\", error_model)\n",
    "em_corrector = SpellCorrector(candidate_gen, error_model, uniform_language_model, noerror_rate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the new spelling corrector, generate corrections for `acress`. How do the rankings of candidates other than `acres` compare to previously, and why do you think that is? What does that tell you about the interaction of the error model and the candidate generator? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target candidate  distance  error_score  lm_score     score\n",
      "0  acress     acres         1    -1.408591  -1.20412 -2.612711\n",
      "1  acress   actress         1    -2.085023  -1.20412 -3.289143\n",
      "2  acress    across         1    -2.106361  -1.20412 -3.310481\n",
      "3  acress    caress         1    -2.425697  -1.20412 -3.629817\n"
     ]
    }
   ],
   "source": [
    "error_model = ErrorModel(\"inputs/errors_corpus.txt\")\n",
    "candidate_gen = CandidateGenerator(1, \"inputs/words.txt\", error_model)\n",
    "em_corrector = SpellCorrector(candidate_gen, error_model, uniform_language_model, noerror_rate=0)\n",
    "\n",
    "corrections = em_corrector.correct_word(\"acress\", 0)\n",
    "\n",
    "print(corrections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to previous outputs, \"actress\" and \"across\" now rank higher than before. This is because the new error model, trained on real data, assigns more realistic probabilities to certain types of spelling changes based on observed error patterns. \n",
    "This shows a well-trained error model can prioritize candidates that reflect more likely human spelling mistakes, thereby improving the accuracy of the spelling corrector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the code cell above, the error model can also be provided as an argument when constructing the candidate generator, so that candidates requiring changes that were not observed in the training data are not generated. This may have implications for the paths associated with candidate generation.\n",
    "\n",
    "2. Using the new candidate generator `candidate_gen`, generate candidates for the non-word `acress` that filter out paths containing unobserved changes. Compare the numbers in both path columns to what you saw under the original candidate generator. How have they changed? Drawing on the observations you made earlier about the influences of paths on error probabilities, what does this tell you about the interaction of the error model and the candidate generator? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  candidate  distance  paths_to_target  paths_from_candidate\n",
      "0     acres         1                2                    80\n",
      "1    caress         1                1                    88\n",
      "2    across         1                1                    74\n",
      "3   actress         1                1                   103\n"
     ]
    }
   ],
   "source": [
    "# Generate candidates for 'acress' with the new candidate generator that filters out unobserved changes\n",
    "filtered_candidates = candidate_gen.candidates(\"acress\")\n",
    "print(filtered_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are updated path counts for candidates of \"acress.\" Specifically, \"acres\" has 2 valid paths to it, while \"caress,\" \"across,\" and \"actress\" each have only 1. By filtering out unlikely paths, the candidate generator enhances the accuracy of the spelling corrector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3: the language model [6 points]\n",
    "\n",
    "Each candidate also needs to be evaluated for how good a sentence it creates when substituted for the target. For this, we use a language model.\n",
    "\n",
    "The codebase for this assignment includes the `run_srilm()` function you saw in Assignment 1. You can use this function to train and save language models, e.g.\n",
    "```python\n",
    "run_srilm(\"ngram-count -order 1 -unk -text inputs/train_100k.txt.gz -lm models/100k_unigram.lm\")\n",
    "```\n",
    "\n",
    "The language model can be read into python using the `arpa.loadf()` method, as follows:\n",
    "```python\n",
    "unigram_language_model = arpa.loadf(\"models/100k_unigram.lm\")[0]\n",
    "```\n",
    "The argument is the path to the language model file. The final `[0]` is required because the method outputs a list of models, which (for models trained with SRILM) will only contain one item.\n",
    "\n",
    "Once a language model has been read, it can be incorporated into the spelling corrector by replacing the appropriate argument, e.g.\n",
    "```python\n",
    "unigram_corrector = SpellCorrector(candidate_gen, error_model, unigram_language_model, noerror_rate=0)\n",
    "```\n",
    "\n",
    "The new corrector can be used to generate corrections for a word in sentential context, e.g.\n",
    "```python\n",
    "unigram_corrector.correct_word(\"she is a comic acress with many awards to her name\", 4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a unigram language model on the file `train_100k.txt.gz` and use it to create a new spelling corrector. Using that corrector, generate corrections for the word `acress` in the sentence `she is a comic acress with many awards to her name`. How do these corrections compare to those previously generated, with just the error model? Can you explain the similarities and/or differences in rankings of candidates across the two correctors? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The command ran successfully\n",
      "   target candidate  distance  position  \\\n",
      "0  acress    across         1         4   \n",
      "1  acress   actress         1         4   \n",
      "2  acress     acres         1         4   \n",
      "3  acress    caress         1         4   \n",
      "\n",
      "                                            sentence  error_score   lm_score  \\\n",
      "0  she is a comic across with many awards to her ...    -2.106361 -66.740294   \n",
      "1  she is a comic actress with many awards to her...    -2.085023 -68.730368   \n",
      "2  she is a comic acres with many awards to her name    -1.408591 -69.415214   \n",
      "3  she is a comic caress with many awards to her ...    -2.425697 -70.328666   \n",
      "\n",
      "       score  \n",
      "0 -68.846655  \n",
      "1 -70.815391  \n",
      "2 -70.823805  \n",
      "3 -72.754363  \n"
     ]
    }
   ],
   "source": [
    "# Train the unigram language model\n",
    "run_srilm(\"ngram-count -order 1 -unk -text inputs/train_100k.txt.gz -lm models/100k_unigram.lm\")\n",
    "\n",
    "# Load the trained unigram language model\n",
    "unigram_language_model = arpa.loadf(\"models/100k_unigram.lm\")[0]\n",
    "\n",
    "# Create a new spelling corrector using the unigram language model\n",
    "unigram_corrector = SpellCorrector(candidate_gen, error_model, unigram_language_model, noerror_rate=0)\n",
    "\n",
    "# Generate corrections for the word 'acress' in context\n",
    "unigram_corrections = unigram_corrector.correct_word(\"she is a comic acress with many awards to her name\", 4)\n",
    "\n",
    "print(unigram_corrections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores have become more negative overall. While the error model focuses on the likelihood of transformations from the misspelled word to the candidates based on observed spelling errors, the unigram model assesses how likely the candidates are in the context of the surrounding sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train a bigram language model on the file `train_100k.txt.gz` and use it to create another new spelling corrector. Using that corrector, repeat the above investigation. What has changed, and why? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The command ran successfully\n",
      "   target candidate  distance  position  \\\n",
      "0  acress   actress         1         4   \n",
      "1  acress    across         1         4   \n",
      "2  acress     acres         1         4   \n",
      "3  acress    caress         1         4   \n",
      "\n",
      "                                            sentence  error_score   lm_score  \\\n",
      "0  she is a comic actress with many awards to her...    -2.085023 -55.475186   \n",
      "1  she is a comic across with many awards to her ...    -2.106361 -59.051406   \n",
      "2  she is a comic acres with many awards to her name    -1.408591 -60.309881   \n",
      "3  she is a comic caress with many awards to her ...    -2.425697 -61.620077   \n",
      "\n",
      "       score  \n",
      "0 -57.560209  \n",
      "1 -61.157767  \n",
      "2 -61.718472  \n",
      "3 -64.045774  \n"
     ]
    }
   ],
   "source": [
    "# Train the bigram language model\n",
    "run_srilm(\"ngram-count -order 2 -unk -text inputs/train_100k.txt.gz -lm models/100k_bigram.lm\")\n",
    "\n",
    "# Load the trained bigram language model\n",
    "bigram_language_model = arpa.loadf(\"models/100k_bigram.lm\")[0]\n",
    "\n",
    "# Create a new spelling corrector using the bigram language model\n",
    "bigram_corrector = SpellCorrector(candidate_gen, error_model, bigram_language_model, noerror_rate=0)\n",
    "\n",
    "# Generate corrections for the word 'acress' in context\n",
    "bigram_corrections = bigram_corrector.correct_word(\"she is a comic acress with many awards to her name\", 4)\n",
    "\n",
    "print(bigram_corrections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lm_scores are less negative compared to the unigram model, indicating better contextual fit. The key difference lies in the bigram model's ability to evaluate the likelihood of word pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compare the two corrections from the two language models for the non-word `acress` in the sentence `she is a talented acress who is known for her comedic timing`. How is the pattern similar to or different from the comparison you just did? Why do you think that is? **[2 points]**\n",
    "\n",
    "   *Hint: think about the fact that the language model score is ultimately based on a corpus of limited size, and remember that language models trained with SRILM use backoff by default.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Corrections:    target candidate  distance  position  \\\n",
      "0  acress    across         1         4   \n",
      "1  acress   actress         1         4   \n",
      "2  acress     acres         1         4   \n",
      "3  acress    caress         1         4   \n",
      "\n",
      "                                            sentence  error_score   lm_score  \\\n",
      "0  she is a talented across who is known for her ...    -2.106361 -79.794828   \n",
      "1  she is a talented actress who is known for her...    -2.085023 -81.784902   \n",
      "2  she is a talented acres who is known for her c...    -1.408591 -82.469748   \n",
      "3  she is a talented caress who is known for her ...    -2.425697 -83.383200   \n",
      "\n",
      "       score  \n",
      "0 -81.901189  \n",
      "1 -83.869925  \n",
      "2 -83.878339  \n",
      "3 -85.808897  \n",
      "Bigram Corrections:    target candidate  distance  position  \\\n",
      "0  acress    across         1         4   \n",
      "1  acress   actress         1         4   \n",
      "2  acress     acres         1         4   \n",
      "3  acress    caress         1         4   \n",
      "\n",
      "                                            sentence  error_score   lm_score  \\\n",
      "0  she is a talented across who is known for her ...    -2.106361 -71.218441   \n",
      "1  she is a talented actress who is known for her...    -2.085023 -72.600318   \n",
      "2  she is a talented acres who is known for her c...    -1.408591 -73.340841   \n",
      "3  she is a talented caress who is known for her ...    -2.425697 -73.787113   \n",
      "\n",
      "       score  \n",
      "0 -73.324802  \n",
      "1 -74.685340  \n",
      "2 -74.749432  \n",
      "3 -76.212810  \n"
     ]
    }
   ],
   "source": [
    "# Generate corrections for 'acress' in a new sentence\n",
    "new_unigram_corrections = unigram_corrector.correct_word(\"she is a talented acress who is known for her comedic timing\", 4)\n",
    "new_bigram_corrections = bigram_corrector.correct_word(\"she is a talented acress who is known for her comedic timing\", 4)\n",
    "\n",
    "# Display the results for the new sentence\n",
    "print(\"Unigram Corrections:\", new_unigram_corrections)\n",
    "print(\"Bigram Corrections:\", new_bigram_corrections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the unigram and bigram models rank the candidates for \"acress\" similarly, with \"actress\" leading. However, the bigram model's scores are less negative, indicating a better contextual fit. This difference arises because the bigram model accounts for word pairs, enhancing its understanding of context compared to the unigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.4: combining models [5 points]\n",
    "\n",
    "A spelling corrector balances the error model and the language model. Often, one model will prefer one candidate, and the other model will prefer another candidate. The choice between the candidates then comes down to how the models are combined.\n",
    "\n",
    "When combining models, we can choose to weight the language model up or down relative to the error model, to offset the balance between them. In the `SpellCorrector` object, this is achieved through the keyword argument `lm_doublings`, which represents the number of times the language model should be doubled in importance relative to the error model. When `lm doublings` is positive, the language model takes on additional weight relative to the error model; when `lm_doublings` is negative, the language model loses weight relative to the error model, and when `lm_doublings` is zero, both models are weighted equally. \n",
    "\n",
    "1. The spelling correctors we have been using so far have a slight bias toward the language model. The code cell below defines one with an extreme bias toward the error model. Compare corrections of your bigram-based corrector and this new corrector for the non-word `mne` in the sentence `if i had a gold mne my life would be easy`. How are they different, and why? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extreme bias corrector output:   target candidate  distance  position  \\\n",
      "0    mne       men         1         5   \n",
      "1    mne      mine         1         5   \n",
      "2    mne      mane         1         5   \n",
      "3    mne        me         1         5   \n",
      "\n",
      "                                     sentence  error_score  lm_score     score  \n",
      "0   if i had a gold men my life would be easy    -1.744293 -0.433346 -2.177639  \n",
      "1  if i had a gold mine my life would be easy    -1.793169 -0.394553 -2.187722  \n",
      "2  if i had a gold mane my life would be easy    -1.775511 -0.462009 -2.237520  \n",
      "3    if i had a gold me my life would be easy    -2.095169 -0.403152 -2.498322  \n",
      "Bigram-based corrector output:   target candidate  distance  position  \\\n",
      "0    mne      mine         1         5   \n",
      "1    mne        me         1         5   \n",
      "2    mne       men         1         5   \n",
      "3    mne      mane         1         5   \n",
      "\n",
      "                                     sentence  error_score   lm_score  \\\n",
      "0  if i had a gold mine my life would be easy    -1.793169 -50.502730   \n",
      "1    if i had a gold me my life would be easy    -2.095169 -51.603499   \n",
      "2   if i had a gold men my life would be easy    -1.744293 -55.468332   \n",
      "3  if i had a gold mane my life would be easy    -1.775511 -59.137134   \n",
      "\n",
      "       score  \n",
      "0 -52.295899  \n",
      "1 -53.698668  \n",
      "2 -57.212625  \n",
      "3 -60.912645  \n"
     ]
    }
   ],
   "source": [
    "extreme_bias_corrector = SpellCorrector(candidate_gen, error_model, bigram_language_model, noerror_rate=0, lm_doublings=-6)\n",
    "bigram_corrector = SpellCorrector(candidate_gen, error_model, bigram_language_model, noerror_rate=0)\n",
    "\n",
    "extreme_bias_correction = extreme_bias_corrector.correct_word(\"if i had a gold mne my life would be easy\", 5)\n",
    "bigram_correction = bigram_corrector.correct_word(\"if i had a gold mne my life would be easy\", 5)\n",
    "\n",
    "print(\"Extreme bias corrector output:\", extreme_bias_correction)\n",
    "print(\"Bigram-based corrector output:\", bigram_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extreme bias corrector prioritizes the error model, suggesting candidates like \"gould\" and \"golds\" for \"mne,\" which are phonetically closer to the misspelled word. In contrast, the bigram corrector would likely provide contextually relevant suggestions based on language model scores. This difference highlights the trade-off between spelling similarity and grammatical coherence in the corrections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now make a new corrector that is exactly the same as the previous one, except with a less extreme error model bias, by setting `lm_doublings` to -3. Compare the rankings of `men` and `me` in the new model to the previous models. How are they different, and why? What does this tell you about how the error model and language model work together? **[2 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extreme bias corrector output:   target candidate  distance  position  \\\n",
      "0    mne       men         1         5   \n",
      "1    mne      mine         1         5   \n",
      "2    mne      mane         1         5   \n",
      "3    mne        me         1         5   \n",
      "\n",
      "                                     sentence  error_score  lm_score     score  \n",
      "0   if i had a gold men my life would be easy    -1.744293 -0.433346 -2.177639  \n",
      "1  if i had a gold mine my life would be easy    -1.793169 -0.394553 -2.187722  \n",
      "2  if i had a gold mane my life would be easy    -1.775511 -0.462009 -2.237520  \n",
      "3    if i had a gold me my life would be easy    -2.095169 -0.403152 -2.498322  \n",
      "Bigram-based corrector output:   target candidate  distance  position  \\\n",
      "0    mne      mine         1         5   \n",
      "1    mne        me         1         5   \n",
      "2    mne       men         1         5   \n",
      "3    mne      mane         1         5   \n",
      "\n",
      "                                     sentence  error_score   lm_score  \\\n",
      "0  if i had a gold mine my life would be easy    -1.793169 -50.502730   \n",
      "1    if i had a gold me my life would be easy    -2.095169 -51.603499   \n",
      "2   if i had a gold men my life would be easy    -1.744293 -55.468332   \n",
      "3  if i had a gold mane my life would be easy    -1.775511 -59.137134   \n",
      "\n",
      "       score  \n",
      "0 -52.295899  \n",
      "1 -53.698668  \n",
      "2 -57.212625  \n",
      "3 -60.912645  \n",
      "Less extreme bias corrector output:   target candidate  distance  position  \\\n",
      "0    mne      mine         1         5   \n",
      "1    mne       men         1         5   \n",
      "2    mne        me         1         5   \n",
      "3    mne      mane         1         5   \n",
      "\n",
      "                                     sentence  error_score  lm_score     score  \n",
      "0  if i had a gold mine my life would be easy    -1.793169 -3.156421 -4.949590  \n",
      "1   if i had a gold men my life would be easy    -1.744293 -3.466771 -5.211064  \n",
      "2    if i had a gold me my life would be easy    -2.095169 -3.225219 -5.320388  \n",
      "3  if i had a gold mane my life would be easy    -1.775511 -3.696071 -5.471582  \n"
     ]
    }
   ],
   "source": [
    "extreme_bias_corrector = SpellCorrector(candidate_gen, error_model, bigram_language_model, noerror_rate=0, lm_doublings=-6)\n",
    "bigram_corrector = SpellCorrector(candidate_gen, error_model, bigram_language_model, noerror_rate=0)\n",
    "less_extreme_bias_corrector = SpellCorrector(candidate_gen, error_model, bigram_language_model, noerror_rate=0, lm_doublings=-3)\n",
    "\n",
    "extreme_bias_correction = extreme_bias_corrector.correct_word(\"if i had a gold mne my life would be easy\", 5)\n",
    "bigram_correction = bigram_corrector.correct_word(\"if i had a gold mne my life would be easy\", 5)\n",
    "less_extreme_bias_correction = less_extreme_bias_corrector.correct_word(\"if i had a gold mne my life would be easy\", 5)\n",
    "\n",
    "print(\"Extreme bias corrector output:\", extreme_bias_correction)\n",
    "print(\"Bigram-based corrector output:\", bigram_correction)\n",
    "print(\"Less extreme bias corrector output:\", less_extreme_bias_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The less extreme bias corrector ranks contextually appropriate candidates like \"men\" and \"me\" higher compared to the extreme bias corrector. The extreme bias model favors phonetic similarities (e.g., \"gould,\" \"golds\"), while the less extreme model incorporates context more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering entire sentences, it's not always possible to know where a spelling error is, or even if there is one, because many spelling errors create real words. The spelling corrector handles this by considering whether each word is or is not an error, based on a parameter that defines how likely it is for a word *not* to be an error. In this codebase, that is handled through the keyword argument `noerror_rate`, passed when the spelling corrector is created.\n",
    "\n",
    "The code cell below shows the use of the `noerror_rate` argument, as well as a method `SpellCorrector.correct_sentence()` that tabulates possible corrections for up to one word anywhere in a sentence. *Note: you will need to replace `bigram_language_model` with the name of your bigram language model for the code to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>candidate</th>\n",
       "      <th>position</th>\n",
       "      <th>sentence</th>\n",
       "      <th>error_score</th>\n",
       "      <th>lm_score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>a rolling stone gathers no moss</td>\n",
       "      <td>-0.002177</td>\n",
       "      <td>-22.188404</td>\n",
       "      <td>-22.190581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moss</td>\n",
       "      <td>mass</td>\n",
       "      <td>5</td>\n",
       "      <td>a rolling stone gathers no mass</td>\n",
       "      <td>-3.952093</td>\n",
       "      <td>-20.385922</td>\n",
       "      <td>-24.338015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moss</td>\n",
       "      <td>moses</td>\n",
       "      <td>5</td>\n",
       "      <td>a rolling stone gathers no moses</td>\n",
       "      <td>-3.284943</td>\n",
       "      <td>-21.152062</td>\n",
       "      <td>-24.437005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moss</td>\n",
       "      <td>most</td>\n",
       "      <td>5</td>\n",
       "      <td>a rolling stone gathers no most</td>\n",
       "      <td>-3.951476</td>\n",
       "      <td>-20.947566</td>\n",
       "      <td>-24.899042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>not</td>\n",
       "      <td>4</td>\n",
       "      <td>a rolling stone gathers not moss</td>\n",
       "      <td>-3.243991</td>\n",
       "      <td>-21.821536</td>\n",
       "      <td>-25.065527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>now</td>\n",
       "      <td>4</td>\n",
       "      <td>a rolling stone gathers now moss</td>\n",
       "      <td>-2.786346</td>\n",
       "      <td>-22.446007</td>\n",
       "      <td>-25.232353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gathers</td>\n",
       "      <td>gather</td>\n",
       "      <td>3</td>\n",
       "      <td>a rolling stone gather no moss</td>\n",
       "      <td>-4.229170</td>\n",
       "      <td>-21.408652</td>\n",
       "      <td>-25.637822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stone</td>\n",
       "      <td>stones</td>\n",
       "      <td>2</td>\n",
       "      <td>a rolling stones gathers no moss</td>\n",
       "      <td>-3.029113</td>\n",
       "      <td>-22.898802</td>\n",
       "      <td>-25.927915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>as</td>\n",
       "      <td>0</td>\n",
       "      <td>as rolling stone gathers no moss</td>\n",
       "      <td>-2.868016</td>\n",
       "      <td>-23.374372</td>\n",
       "      <td>-26.242388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>nor</td>\n",
       "      <td>4</td>\n",
       "      <td>a rolling stone gathers nor moss</td>\n",
       "      <td>-3.084714</td>\n",
       "      <td>-23.206808</td>\n",
       "      <td>-26.291522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>at</td>\n",
       "      <td>0</td>\n",
       "      <td>at rolling stone gathers no moss</td>\n",
       "      <td>-3.079181</td>\n",
       "      <td>-23.840281</td>\n",
       "      <td>-26.919462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a</td>\n",
       "      <td>an</td>\n",
       "      <td>0</td>\n",
       "      <td>an rolling stone gathers no moss</td>\n",
       "      <td>-3.083129</td>\n",
       "      <td>-24.119789</td>\n",
       "      <td>-27.202918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stone</td>\n",
       "      <td>stoner</td>\n",
       "      <td>2</td>\n",
       "      <td>a rolling stoner gathers no moss</td>\n",
       "      <td>-3.306012</td>\n",
       "      <td>-27.043765</td>\n",
       "      <td>-30.349777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stone</td>\n",
       "      <td>stoned</td>\n",
       "      <td>2</td>\n",
       "      <td>a rolling stoned gathers no moss</td>\n",
       "      <td>-3.388860</td>\n",
       "      <td>-27.112819</td>\n",
       "      <td>-30.501679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rolling</td>\n",
       "      <td>rollings</td>\n",
       "      <td>1</td>\n",
       "      <td>a rollings stone gathers no moss</td>\n",
       "      <td>-4.254199</td>\n",
       "      <td>-27.340329</td>\n",
       "      <td>-31.594528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rolling</td>\n",
       "      <td>rilling</td>\n",
       "      <td>1</td>\n",
       "      <td>a rilling stone gathers no moss</td>\n",
       "      <td>-4.628900</td>\n",
       "      <td>-27.340329</td>\n",
       "      <td>-31.969228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rolling</td>\n",
       "      <td>trolling</td>\n",
       "      <td>1</td>\n",
       "      <td>a trolling stone gathers no moss</td>\n",
       "      <td>-4.739309</td>\n",
       "      <td>-27.492726</td>\n",
       "      <td>-32.232034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target candidate position                          sentence  error_score  \\\n",
       "0        --        --       --   a rolling stone gathers no moss    -0.002177   \n",
       "1      moss      mass        5   a rolling stone gathers no mass    -3.952093   \n",
       "2      moss     moses        5  a rolling stone gathers no moses    -3.284943   \n",
       "3      moss      most        5   a rolling stone gathers no most    -3.951476   \n",
       "4        no       not        4  a rolling stone gathers not moss    -3.243991   \n",
       "5        no       now        4  a rolling stone gathers now moss    -2.786346   \n",
       "6   gathers    gather        3    a rolling stone gather no moss    -4.229170   \n",
       "7     stone    stones        2  a rolling stones gathers no moss    -3.029113   \n",
       "8         a        as        0  as rolling stone gathers no moss    -2.868016   \n",
       "9        no       nor        4  a rolling stone gathers nor moss    -3.084714   \n",
       "10        a        at        0  at rolling stone gathers no moss    -3.079181   \n",
       "11        a        an        0  an rolling stone gathers no moss    -3.083129   \n",
       "12    stone    stoner        2  a rolling stoner gathers no moss    -3.306012   \n",
       "13    stone    stoned        2  a rolling stoned gathers no moss    -3.388860   \n",
       "14  rolling  rollings        1  a rollings stone gathers no moss    -4.254199   \n",
       "15  rolling   rilling        1   a rilling stone gathers no moss    -4.628900   \n",
       "16  rolling  trolling        1  a trolling stone gathers no moss    -4.739309   \n",
       "\n",
       "     lm_score      score  \n",
       "0  -22.188404 -22.190581  \n",
       "1  -20.385922 -24.338015  \n",
       "2  -21.152062 -24.437005  \n",
       "3  -20.947566 -24.899042  \n",
       "4  -21.821536 -25.065527  \n",
       "5  -22.446007 -25.232353  \n",
       "6  -21.408652 -25.637822  \n",
       "7  -22.898802 -25.927915  \n",
       "8  -23.374372 -26.242388  \n",
       "9  -23.206808 -26.291522  \n",
       "10 -23.840281 -26.919462  \n",
       "11 -24.119789 -27.202918  \n",
       "12 -27.043765 -30.349777  \n",
       "13 -27.112819 -30.501679  \n",
       "14 -27.340329 -31.594528  \n",
       "15 -27.340329 -31.969228  \n",
       "16 -27.492726 -32.232034  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_corrector = SpellCorrector(candidate_gen, error_model, bigram_language_model, noerror_rate=0.995, lm_doublings=0)\n",
    "sentence_corrector.correct_sentence(\"a rolling stone gathers no moss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the case of the sentence `a rolling stone gathers no moss`, a `noerror_rate` of 0.995 leads to the correct observation that there are no spelling errors. For the sentence `the big hose sits on a tiny lot`, this same value also leads to the prediction that there are no spelling errors, even though `hose` should be corrected to `house`! Experiment with different values of `noerror_rate` to find a few values of `noerror_rate` that yield the correct observation for both sentences (do not change any other aspects of the spelling corrector). What happens if you make the `noerror_rate` *too* low? **[1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing noerror_rate = 0.9\n",
      "\n",
      "Corrections for 'a rolling stone gathers no moss':\n",
      "     target candidate position                          sentence  error_score  \\\n",
      "0        --        --       --   a rolling stone gathers no moss    -0.045757   \n",
      "1      moss      mass        5   a rolling stone gathers no mass    -2.651063   \n",
      "2      moss     moses        5  a rolling stone gathers no moses    -1.983913   \n",
      "3      moss      most        5   a rolling stone gathers no most    -2.650446   \n",
      "4        no       not        4  a rolling stone gathers not moss    -1.942961   \n",
      "5        no       now        4  a rolling stone gathers now moss    -1.485316   \n",
      "6   gathers    gather        3    a rolling stone gather no moss    -2.928140   \n",
      "7     stone    stones        2  a rolling stones gathers no moss    -1.728083   \n",
      "8         a        as        0  as rolling stone gathers no moss    -1.566986   \n",
      "9        no       nor        4  a rolling stone gathers nor moss    -1.783684   \n",
      "10        a        at        0  at rolling stone gathers no moss    -1.778151   \n",
      "11        a        an        0  an rolling stone gathers no moss    -1.782099   \n",
      "12    stone    stoner        2  a rolling stoner gathers no moss    -2.004982   \n",
      "13    stone    stoned        2  a rolling stoned gathers no moss    -2.087830   \n",
      "14  rolling  rollings        1  a rollings stone gathers no moss    -2.953169   \n",
      "15  rolling   rilling        1   a rilling stone gathers no moss    -3.327870   \n",
      "16  rolling  trolling        1  a trolling stone gathers no moss    -3.438279   \n",
      "\n",
      "     lm_score      score  \n",
      "0  -22.188404 -22.234161  \n",
      "1  -20.385922 -23.036985  \n",
      "2  -21.152062 -23.135975  \n",
      "3  -20.947566 -23.598012  \n",
      "4  -21.821536 -23.764497  \n",
      "5  -22.446007 -23.931323  \n",
      "6  -21.408652 -24.336792  \n",
      "7  -22.898802 -24.626885  \n",
      "8  -23.374372 -24.941358  \n",
      "9  -23.206808 -24.990492  \n",
      "10 -23.840281 -25.618432  \n",
      "11 -24.119789 -25.901888  \n",
      "12 -27.043765 -29.048747  \n",
      "13 -27.112819 -29.200649  \n",
      "14 -27.340329 -30.293498  \n",
      "15 -27.340329 -30.668198  \n",
      "16 -27.492726 -30.931004  \n",
      "\n",
      "Corrections for 'the big hose sits on a tiny lot':\n",
      "   target candidate position                          sentence  error_score  \\\n",
      "0    hose     house        2  the big house sits on a tiny lot    -1.758015   \n",
      "1      --        --       --   the big hose sits on a tiny lot    -0.045757   \n",
      "2    hose     whose        2  the big whose sits on a tiny lot    -2.471982   \n",
      "3    hose     horse        2  the big horse sits on a tiny lot    -2.046825   \n",
      "4     lot      lost        7  the big hose sits on a tiny lost    -2.189664   \n",
      "5     lot      loot        7  the big hose sits on a tiny loot    -1.528973   \n",
      "6    sits     sites        3  the big hose sites on a tiny lot    -1.945249   \n",
      "7     lot       lit        7   the big hose sits on a tiny lit    -2.776078   \n",
      "8    sits       sit        3    the big hose sit on a tiny lot    -2.691965   \n",
      "9      on        in        4   the big hose sits in a tiny lot    -2.420506   \n",
      "10   sits      site        3   the big hose site on a tiny lot    -3.147367   \n",
      "11   tiny      tony        6   the big hose sits on a tony lot    -2.560305   \n",
      "12    big       bag        1   the bag hose sits on a tiny lot    -2.672098   \n",
      "13     on        of        4   the big hose sits of a tiny lot    -2.511883   \n",
      "14    big       bid        1   the bid hose sits on a tiny lot    -2.674402   \n",
      "15   tiny     tinny        6  the big hose sits on a tinny lot    -1.641994   \n",
      "16      a        an        5  the big hose sits on an tiny lot    -1.782099   \n",
      "17    big       beg        1   the beg hose sits on a tiny lot    -2.204120   \n",
      "18   tiny     tinty        6  the big hose sits on a tinty lot    -2.235528   \n",
      "19    the      they        0  they big hose sits on a tiny lot    -2.288175   \n",
      "20    the        he        0    he big hose sits on a tiny lot    -2.536919   \n",
      "21    the      then        0  then big hose sits on a tiny lot    -1.972066   \n",
      "22      a        as        5  the big hose sits on as tiny lot    -1.566986   \n",
      "23     on       won        4  the big hose sits won a tiny lot    -2.191155   \n",
      "24      a        at        5  the big hose sits on at tiny lot    -1.778151   \n",
      "\n",
      "     lm_score      score  \n",
      "0  -23.846362 -25.604377  \n",
      "1  -26.625472 -26.671230  \n",
      "2  -24.696572 -27.168554  \n",
      "3  -25.131694 -27.178519  \n",
      "4  -25.633330 -27.822994  \n",
      "5  -27.183830 -28.712803  \n",
      "6  -26.799997 -28.745245  \n",
      "7  -26.048303 -28.824382  \n",
      "8  -26.211514 -28.903479  \n",
      "9  -26.941151 -29.361657  \n",
      "10 -26.515683 -29.663050  \n",
      "11 -27.404326 -29.964631  \n",
      "12 -27.480375 -30.152472  \n",
      "13 -27.749620 -30.261503  \n",
      "14 -27.616262 -30.290664  \n",
      "15 -28.826403 -30.468397  \n",
      "16 -29.207788 -30.989888  \n",
      "17 -28.822059 -31.026179  \n",
      "18 -28.826403 -31.061931  \n",
      "19 -29.084908 -31.373083  \n",
      "20 -28.880806 -31.417725  \n",
      "21 -29.573189 -31.545255  \n",
      "22 -30.315852 -31.882838  \n",
      "23 -29.693305 -31.884460  \n",
      "24 -30.678198 -32.456349  \n",
      "\n",
      "Testing noerror_rate = 0.5\n",
      "\n",
      "Corrections for 'a rolling stone gathers no moss':\n",
      "     target candidate position                          sentence  error_score  \\\n",
      "0      moss      mass        5   a rolling stone gathers no mass    -1.952093   \n",
      "1      moss     moses        5  a rolling stone gathers no moses    -1.284943   \n",
      "2        --        --       --   a rolling stone gathers no moss    -0.301030   \n",
      "3      moss      most        5   a rolling stone gathers no most    -1.951476   \n",
      "4        no       not        4  a rolling stone gathers not moss    -1.243991   \n",
      "5        no       now        4  a rolling stone gathers now moss    -0.786346   \n",
      "6   gathers    gather        3    a rolling stone gather no moss    -2.229170   \n",
      "7     stone    stones        2  a rolling stones gathers no moss    -1.029113   \n",
      "8         a        as        0  as rolling stone gathers no moss    -0.868016   \n",
      "9        no       nor        4  a rolling stone gathers nor moss    -1.084714   \n",
      "10        a        at        0  at rolling stone gathers no moss    -1.079181   \n",
      "11        a        an        0  an rolling stone gathers no moss    -1.083129   \n",
      "12    stone    stoner        2  a rolling stoner gathers no moss    -1.306012   \n",
      "13    stone    stoned        2  a rolling stoned gathers no moss    -1.388860   \n",
      "14  rolling  rollings        1  a rollings stone gathers no moss    -2.254199   \n",
      "15  rolling   rilling        1   a rilling stone gathers no moss    -2.628900   \n",
      "16  rolling  trolling        1  a trolling stone gathers no moss    -2.739309   \n",
      "\n",
      "     lm_score      score  \n",
      "0  -20.385922 -22.338015  \n",
      "1  -21.152062 -22.437005  \n",
      "2  -22.188404 -22.489434  \n",
      "3  -20.947566 -22.899042  \n",
      "4  -21.821536 -23.065527  \n",
      "5  -22.446007 -23.232353  \n",
      "6  -21.408652 -23.637822  \n",
      "7  -22.898802 -23.927915  \n",
      "8  -23.374372 -24.242388  \n",
      "9  -23.206808 -24.291522  \n",
      "10 -23.840281 -24.919462  \n",
      "11 -24.119789 -25.202918  \n",
      "12 -27.043765 -28.349777  \n",
      "13 -27.112819 -28.501679  \n",
      "14 -27.340329 -29.594528  \n",
      "15 -27.340329 -29.969228  \n",
      "16 -27.492726 -30.232034  \n",
      "\n",
      "Corrections for 'the big hose sits on a tiny lot':\n",
      "   target candidate position                          sentence  error_score  \\\n",
      "0    hose     house        2  the big house sits on a tiny lot    -1.059045   \n",
      "1    hose     whose        2  the big whose sits on a tiny lot    -1.773012   \n",
      "2    hose     horse        2  the big horse sits on a tiny lot    -1.347855   \n",
      "3    hose     those        2  the big those sits on a tiny lot    -2.514105   \n",
      "4      --        --       --   the big hose sits on a tiny lot    -0.301030   \n",
      "5     lot      lost        7  the big hose sits on a tiny lost    -1.490694   \n",
      "6     lot      loot        7  the big hose sits on a tiny loot    -0.830003   \n",
      "7    sits     sites        3  the big hose sites on a tiny lot    -1.246279   \n",
      "8     lot       lit        7   the big hose sits on a tiny lit    -2.077108   \n",
      "9    sits       sit        3    the big hose sit on a tiny lot    -1.992995   \n",
      "10     on        in        4   the big hose sits in a tiny lot    -1.721536   \n",
      "11   sits      site        3   the big hose site on a tiny lot    -2.448397   \n",
      "12   tiny      tony        6   the big hose sits on a tony lot    -1.861335   \n",
      "13    big       bag        1   the bag hose sits on a tiny lot    -1.973128   \n",
      "14     on        of        4   the big hose sits of a tiny lot    -1.812913   \n",
      "15    big       bid        1   the bid hose sits on a tiny lot    -1.975432   \n",
      "16   tiny     tinny        6  the big hose sits on a tinny lot    -0.943024   \n",
      "17      a        an        5  the big hose sits on an tiny lot    -1.083129   \n",
      "18    big       beg        1   the beg hose sits on a tiny lot    -1.505150   \n",
      "19   tiny     tinty        6  the big hose sits on a tinty lot    -1.536558   \n",
      "20    the      they        0  they big hose sits on a tiny lot    -1.589205   \n",
      "21    the        he        0    he big hose sits on a tiny lot    -1.837949   \n",
      "22    the      then        0  then big hose sits on a tiny lot    -1.273096   \n",
      "23      a        as        5  the big hose sits on as tiny lot    -0.868016   \n",
      "24     on       won        4  the big hose sits won a tiny lot    -1.492185   \n",
      "25      a        at        5  the big hose sits on at tiny lot    -1.079181   \n",
      "\n",
      "     lm_score      score  \n",
      "0  -23.846362 -24.905407  \n",
      "1  -24.696572 -26.469584  \n",
      "2  -25.131694 -26.479549  \n",
      "3  -24.352433 -26.866538  \n",
      "4  -26.625472 -26.926502  \n",
      "5  -25.633330 -27.124024  \n",
      "6  -27.183830 -28.013833  \n",
      "7  -26.799997 -28.046275  \n",
      "8  -26.048303 -28.125412  \n",
      "9  -26.211514 -28.204509  \n",
      "10 -26.941151 -28.662687  \n",
      "11 -26.515683 -28.964080  \n",
      "12 -27.404326 -29.265661  \n",
      "13 -27.480375 -29.453502  \n",
      "14 -27.749620 -29.562533  \n",
      "15 -27.616262 -29.591694  \n",
      "16 -28.826403 -29.769427  \n",
      "17 -29.207788 -30.290918  \n",
      "18 -28.822059 -30.327209  \n",
      "19 -28.826403 -30.362961  \n",
      "20 -29.084908 -30.674113  \n",
      "21 -28.880806 -30.718755  \n",
      "22 -29.573189 -30.846285  \n",
      "23 -30.315852 -31.183868  \n",
      "24 -29.693305 -31.185490  \n",
      "25 -30.678198 -31.757379  \n",
      "\n",
      "Testing noerror_rate = 0.1\n",
      "\n",
      "Corrections for 'a rolling stone gathers no moss':\n",
      "     target candidate position                          sentence  error_score  \\\n",
      "0      moss      mass        5   a rolling stone gathers no mass    -1.696820   \n",
      "1      moss     moses        5  a rolling stone gathers no moses    -1.029671   \n",
      "2      moss      most        5   a rolling stone gathers no most    -1.696204   \n",
      "3        no       not        4  a rolling stone gathers not moss    -0.988719   \n",
      "4        no       now        4  a rolling stone gathers now moss    -0.531073   \n",
      "5        --        --       --   a rolling stone gathers no moss    -1.000000   \n",
      "6   gathers    gather        3    a rolling stone gather no moss    -1.973897   \n",
      "7     stone    stones        2  a rolling stones gathers no moss    -0.773841   \n",
      "8         a        as        0  as rolling stone gathers no moss    -0.612743   \n",
      "9        no       nor        4  a rolling stone gathers nor moss    -0.829441   \n",
      "10        a        at        0  at rolling stone gathers no moss    -0.823909   \n",
      "11        a        an        0  an rolling stone gathers no moss    -0.827857   \n",
      "12    stone    stoner        2  a rolling stoner gathers no moss    -1.050740   \n",
      "13    stone    stoned        2  a rolling stoned gathers no moss    -1.133588   \n",
      "14  rolling  rollings        1  a rollings stone gathers no moss    -1.998926   \n",
      "15  rolling   rilling        1   a rilling stone gathers no moss    -2.373627   \n",
      "16  rolling  trolling        1  a trolling stone gathers no moss    -2.484036   \n",
      "\n",
      "     lm_score      score  \n",
      "0  -20.385922 -22.082742  \n",
      "1  -21.152062 -22.181733  \n",
      "2  -20.947566 -22.643770  \n",
      "3  -21.821536 -22.810255  \n",
      "4  -22.446007 -22.977080  \n",
      "5  -22.188404 -23.188404  \n",
      "6  -21.408652 -23.382549  \n",
      "7  -22.898802 -23.672642  \n",
      "8  -23.374372 -23.987116  \n",
      "9  -23.206808 -24.036250  \n",
      "10 -23.840281 -24.664190  \n",
      "11 -24.119789 -24.947646  \n",
      "12 -27.043765 -28.094505  \n",
      "13 -27.112819 -28.246407  \n",
      "14 -27.340329 -29.339255  \n",
      "15 -27.340329 -29.713956  \n",
      "16 -27.492726 -29.976762  \n",
      "\n",
      "Corrections for 'the big hose sits on a tiny lot':\n",
      "   target candidate position                          sentence  error_score  \\\n",
      "0    hose     house        2  the big house sits on a tiny lot    -0.803772   \n",
      "1    hose     whose        2  the big whose sits on a tiny lot    -1.517739   \n",
      "2    hose     horse        2  the big horse sits on a tiny lot    -1.092583   \n",
      "3    hose     those        2  the big those sits on a tiny lot    -2.258832   \n",
      "4     lot      lost        7  the big hose sits on a tiny lost    -1.235422   \n",
      "5      --        --       --   the big hose sits on a tiny lot    -1.000000   \n",
      "6     lot      loot        7  the big hose sits on a tiny loot    -0.574730   \n",
      "7    sits     sites        3  the big hose sites on a tiny lot    -0.991006   \n",
      "8     lot       lit        7   the big hose sits on a tiny lit    -1.821836   \n",
      "9    sits       sit        3    the big hose sit on a tiny lot    -1.737723   \n",
      "10     on        in        4   the big hose sits in a tiny lot    -1.466263   \n",
      "11   sits      site        3   the big hose site on a tiny lot    -2.193125   \n",
      "12   tiny      tony        6   the big hose sits on a tony lot    -1.606063   \n",
      "13    big       bag        1   the bag hose sits on a tiny lot    -1.717855   \n",
      "14     on        of        4   the big hose sits of a tiny lot    -1.557641   \n",
      "15    big       bid        1   the bid hose sits on a tiny lot    -1.720159   \n",
      "16   tiny     tinny        6  the big hose sits on a tinny lot    -0.687751   \n",
      "17      a        an        5  the big hose sits on an tiny lot    -0.827857   \n",
      "18    big       beg        1   the beg hose sits on a tiny lot    -1.249877   \n",
      "19   tiny     tinty        6  the big hose sits on a tinty lot    -1.281286   \n",
      "20    the      they        0  they big hose sits on a tiny lot    -1.333932   \n",
      "21    the        he        0    he big hose sits on a tiny lot    -1.582676   \n",
      "22    the      then        0  then big hose sits on a tiny lot    -1.017824   \n",
      "23      a        as        5  the big hose sits on as tiny lot    -0.612743   \n",
      "24     on       won        4  the big hose sits won a tiny lot    -1.236912   \n",
      "25      a        at        5  the big hose sits on at tiny lot    -0.823909   \n",
      "\n",
      "     lm_score      score  \n",
      "0  -23.846362 -24.650134  \n",
      "1  -24.696572 -26.214311  \n",
      "2  -25.131694 -26.224277  \n",
      "3  -24.352433 -26.611265  \n",
      "4  -25.633330 -26.868752  \n",
      "5  -26.625472 -27.625472  \n",
      "6  -27.183830 -27.758560  \n",
      "7  -26.799997 -27.791003  \n",
      "8  -26.048303 -27.870139  \n",
      "9  -26.211514 -27.949237  \n",
      "10 -26.941151 -28.407415  \n",
      "11 -26.515683 -28.708807  \n",
      "12 -27.404326 -29.010389  \n",
      "13 -27.480375 -29.198230  \n",
      "14 -27.749620 -29.307261  \n",
      "15 -27.616262 -29.336422  \n",
      "16 -28.826403 -29.514154  \n",
      "17 -29.207788 -30.035645  \n",
      "18 -28.822059 -30.071936  \n",
      "19 -28.826403 -30.107689  \n",
      "20 -29.084908 -30.418840  \n",
      "21 -28.880806 -30.463482  \n",
      "22 -29.573189 -30.591013  \n",
      "23 -30.315852 -30.928595  \n",
      "24 -29.693305 -30.930218  \n",
      "25 -30.678198 -31.502106  \n"
     ]
    }
   ],
   "source": [
    "noerror_rates = [0.9, 0.5, 0.1]  \n",
    "\n",
    "for rate in noerror_rates:\n",
    "    sentence_corrector = SpellCorrector(candidate_gen, error_model, bigram_language_model, noerror_rate=rate, lm_doublings=0)\n",
    "    print(f\"\\nTesting noerror_rate = {rate}\")\n",
    "    \n",
    "    # Test both sentences\n",
    "    result1 = sentence_corrector.correct_sentence(\"a rolling stone gathers no moss\")\n",
    "    result2 = sentence_corrector.correct_sentence(\"the big hose sits on a tiny lot\")\n",
    "    \n",
    "    print(\"\\nCorrections for 'a rolling stone gathers no moss':\")\n",
    "    print(result1)\n",
    "    \n",
    "    print(\"\\nCorrections for 'the big hose sits on a tiny lot':\")\n",
    "    print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with the noerror_rate shows that values around 0.995 correctly identify no errors in \"a rolling stone gathers no moss,\" while lower values like 0.8 correctly identify \"hose\" as an error in \"the big hose sits on a tiny lot\"; however, setting it too low can lead to excessive false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Minimum edit distance [25 points]\n",
    "\n",
    "Many noisy channel models require finding the best path through a series of steps, such as the best sequence of words for a sentence where all words may or may not contain spelling errors. The general algorithm for finding such a path is known as the Viterbi algorithm. A related algorithm, the minimum edit distance algorithm, can be used to find the smallest number of letter-changes that are required to turn one string into another, and identify what these letter-changes are, both of which are important for a noisy channel spelling corrector.\n",
    "\n",
    "In this part of the assignment, you will implement an algorithm to find the minimum edit distance between two strings and extend it to consider new error costs. You will not complete the step of tracing back to identify the required sequence of letter-changes (not because it is too difficult, but because it requires rewriting all of your functions to keep track of additional structure, which would create a lot of extra work)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the code cell below to import the packages and autotesting functions for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tester import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: edit cost [4 points]\n",
    "\n",
    "As discussed in class, the minimum edit distance algorithm operates in a stepwise manner, with each step identifying the smallest number of letter-changes from a *source* substring to a *target* substring. In this framework, a letter-change is known as an *edit*, and each kind of edit is associated with a particular *cost*.\n",
    "\n",
    "Each edit represents a movement from a *previous* (source, target) substring pair to a *new* (source, target) substring pair. In this movement, one or both of the source and target will gain a new character appended at their right edge. We will at first consider three kinds of edits, represented by three different kinds of movements:  \n",
    "- **insertion**: source stays the same, target gains a character; e.g. (*inte*, *exec*) > (*inte*, *execu*). This is insertion because the best path from the previous source to previous target can still be used, as long as the gained character (*u*) is then inserted at the end of the previous target.  \n",
    "- **deletion**: source gains a character, target stays the same; e.g. (*inte*, *exec*) > (*inten*, *exec*). This is deletion because the best path from the previous source to previous target can still be used, as long as the gained character (*n*) is removed from the end of the new source first.  \n",
    "- **substitution**: source and target both gain a character; e.g. (*inte*, *exec*) > (*inten*, *execu*). This is really a kind of double-insertion or double-deletion: the best path from the previous source to previous target can still be used, as long as the gained characters (*n*, *u*) are also added to or deleted from the end of the new source and target. We call it substitution because the same thing happens to both the source and the target, except with one gained character substituted for another.\n",
    "\n",
    "We will consider standard costs for these edits, which gives rise to the *Levenshtein distance* between two strings.  \n",
    "- **insertion**: costs 1 (no matter what)  \n",
    "- **deletion**: costs 1 (no matter what)  \n",
    "- **substitution**: costs 0 if the gained characters are identical; otherwise 2  \n",
    "\n",
    "Complete the function `lev_edit_cost()` that takes as arguments a previous (source, target) substring pair and a new (source, target) substring pair, identifies the edit associated with the movement from the previous pair to the new pair, and returns the cost of that edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lev_edit_cost(prev_pair, new_pair):\n",
    "    \"\"\"Returns the cost associated with an edit, identified by comparing a previous\n",
    "    (source, target) substring pair with a new (source, target) substring pair.\n",
    "    Assumes Levenshtein costs: 1 for insertion and deletion, and 0/2 for substitution.\n",
    "    \"\"\"\n",
    "    prev_source, prev_target = prev_pair\n",
    "    new_source, new_target = new_pair\n",
    "    \n",
    "    # Check if an insertion occurred\n",
    "    if len(new_source) == len(prev_source) and len(new_target) == len(prev_target) + 1:\n",
    "        return 1  # Insertion cost\n",
    "    # Check if a deletion occurred\n",
    "    elif len(new_source) == len(prev_source) + 1 and len(new_target) == len(prev_target):\n",
    "        return 1  # Deletion cost\n",
    "    # Check for substitution\n",
    "    elif len(new_source) == len(prev_source) + 1 and len(new_target) == len(prev_target) + 1:\n",
    "        if new_source[-1] == new_target[-1]:\n",
    "            return 0  # No cost for same character\n",
    "        else:\n",
    "            return 2  # Cost for different characters\n",
    "    return math.inf  # Not a valid edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether your function works as expected, run the following code cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2.1: CORRECT. Points: 4/4\n"
     ]
    }
   ],
   "source": [
    "test(lev_edit_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: step distance [4 points]\n",
    "\n",
    "At each step in the algorithm, to find the shortest distance between a new (source, target) pair, the edits from three different previous (source, target) pairs are considered. For each edit, the shortest distance between the corresponding previous (source, target) is already known. The distance to the new (source, target) pair that makes use of that edit is obtained by adding the cost of the edit to the known distance between the (source, target) pair. Each edit gives rise to a distance, and the smallest of these distances represents the shortest distance between the new (source, target) pair.\n",
    "\n",
    "Complete the function `step_distance()`, which compares the distances using the three paths to a new (source, target) pair and returns the lowest one. The function takes as arguments a new (source, target) string pair (e.g. `(\"inte\", \"exec\")`), as well as a list of 3 tuples (in general, there may be more than 3, so make sure you iterate over this list rather than unpacking it). Each tuple has two items: firstly, a possible previous (source, target) string pair; and secondly, the known shortest distance between that previous source and target. For example, the list may look like `[((\"int\", \"exec\"), 7), ((\"inte\", \"exe\"), 5), ((\"int\", \"exe\"), 6)]`.\n",
    "\n",
    "The `step_distance()` function has a keyword argument `edit_cost` that represents an edit cost function. When calculating edit costs, you should use `edit_cost(...)` rather than directly using a particular edit cost function such as `lev_edit_cost(...)`, so that `step_distance()` can be used with different edit costs easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_distance(new_pair, possible_prev_steps, edit_cost=lev_edit_cost):\n",
    "    \"\"\"Calculates the minimum distance to a new (source, target) pair\n",
    "    based on the previous pairs and their known distances.\n",
    "    \"\"\"\n",
    "    min_distance = math.inf\n",
    "    for prev_pair, distance in possible_prev_steps:\n",
    "        cost = edit_cost(prev_pair, new_pair)\n",
    "        min_distance = min(min_distance, distance + cost)\n",
    "    return min_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether your function works as expected, run the following code cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2.2: CORRECT. Points: 4/4\n"
     ]
    }
   ],
   "source": [
    "test(step_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: initializing the search table [2 points]\n",
    "\n",
    "As the minimum edit algorithm proceeds, it fills in cells in a large table. For efficiency reasons, it is useful to construct this table in advance. Some cells are filled in automatically as part of the initialization process; others can be given dummy values to be overwritten when the algorithm runs.\n",
    "\n",
    "The size of the table is determined by the size of the source and target words. You may assume that each word has already had a start symbol added at the beginning. The table should have one row for every character in the source word (including the start symbol), and one column for every character in the target word (including the start symbol).\n",
    "\n",
    "The first row and column of the table are filled in as part of the initialization process. The first row should consist of the numbers 0 through to the length of the target, minus one (i.e. excluding the start symbol). The first column should consist of the numbers 0 through to the length of the source, minus one (i.e. excluding the start symbol).\n",
    "\n",
    "Complete the function `init_search_table()` that takes source and target strings as arguments and returns a list of lists representing the initialized table. Each list inside the list-of-lists represents a row in the table; values at the same position in different lists represent a column in the table. For example, `init_search_table(\">no\", \">yes\")` should return `[[0, 1, 2, 3], [1, None, None, None], [2, None, None, None]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_search_table(source, target):\n",
    "    \n",
    "    table = [[None] * len(target) for _ in range(len(source))]\n",
    "\n",
    "    for j in range(len(target)):\n",
    "        table[0][j] = j \n",
    "\n",
    "    for i in range(len(source)):\n",
    "        table[i][0] = i  \n",
    "        \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to test your function on the example `init_search_table(\">no\", \">yes\")`. The tester function converts your table into a pandas DataFrame so that it can be read more easily (note that `NaN` is the pandas equivalent of `None`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: init_search_table(\">no\", \">yes\")\n",
      "Your output:\n",
      "\n",
      "   >    y    e    s\n",
      ">  0  1.0  2.0  3.0\n",
      "n  1  NaN  NaN  NaN\n",
      "o  2  NaN  NaN  NaN\n",
      "\n",
      "Task 2.3: CORRECT. Points: 2/2\n"
     ]
    }
   ],
   "source": [
    "test(init_search_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4: filling in the search table [5 points]\n",
    "\n",
    "The minimum edit distance algorithm fills in a search table one cell at a time, based on consideration of the ways of stepping to that cell from the left, above, or diagonally-left above. This consideration draws upon the values already in the table, as well as the corresponding substrings of the source and target strings (which are assumed to have already had the start symbol added at the beginning).\n",
    "\n",
    "The cell `table[i][j]` represents the shortest distance between the substrings (`source[:i+1]`, `target[:j+1]`). The value for this cell can be determined from the `step_distance()` function, based on consideration of the substrings and shortest distances corresponding to `table[i-1][j-1]`, `table[i-1][j]`, and `table[i][j-1]`. Since the first row and column were filled in at initialization, the three required shortest distances will be known if the rows and columns are iterated over in consecutive (increasing index) order.\n",
    "\n",
    "Complete the function `complete_search_table()`, which takes as arguments a source string, a target string, and an initialized search table, and returns a completed search table. The function also takes a keyword argument `edit_cost` representing a function used to calculate the costs of edits, which should be passed along when calling `step_distance()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_search_table(source, target, table, edit_cost=lev_edit_cost):\n",
    "    for i in range(1, len(source)):\n",
    "        for j in range(1, len(target)):\n",
    "            possible_prev_steps = [\n",
    "                ((source[:i], target[:j]), table[i-1][j-1]),  \n",
    "                ((source[:i], target[:j+1]), table[i-1][j]),  \n",
    "                ((source[:i+1], target[:j]), table[i][j-1])   \n",
    "            ]\n",
    "\n",
    "            table[i][j] = step_distance((source[:i+1], target[:j+1]), possible_prev_steps, edit_cost=edit_cost)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to test your function with `\">intention\"` as the source and `\">execution\"` as the target. The tester function converts your table into a pandas DataFrame so that it can be read more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input: complete_search_table(\">intention\", \">execution\", table), where table is the correctly initialized table for this source and target\n",
      "Your output:\n",
      "\n",
      "   >  e  x   e   c   u   t   i   o   n\n",
      ">  0  1  2   3   4   5   6   7   8   9\n",
      "i  1  2  3   4   5   6   7   6   7   8\n",
      "n  2  3  4   5   6   7   8   7   8   7\n",
      "t  3  4  5   6   7   8   7   8   9   8\n",
      "e  4  3  4   5   6   7   8   9  10   9\n",
      "n  5  4  5   6   7   8   9  10  11  10\n",
      "t  6  5  6   7   8   9   8   9  10  11\n",
      "i  7  6  7   8   9  10   9   8   9  10\n",
      "o  8  7  8   9  10  11  10   9   8   9\n",
      "n  9  8  9  10  11  12  11  10   9   8\n",
      "\n",
      "Task 2.4: CORRECT. Points: 5/5\n"
     ]
    }
   ],
   "source": [
    "test(complete_search_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.5: putting it all together [2 points]\n",
    "\n",
    "Once a search table has been filled in, the minimum edit distance between the strings is the value in the bottom-right corner.\n",
    "\n",
    "Complete the function `min_edit_distance()`, which takes as arguments a source string, a target string, and a keyword argument `edit_cost` representing a function used to calculate edit costs, and returns the minimum edit distance from the source to the target string under the edit cost function. The first thing your function will need to do is add a start symbol before the source and target strings; you should use `>` for this (note this is different to `#` as used in lectures and readings). Once the strings have the start symbol, you should be able to use the functions `init_search_table()` and `complete_search_table()` that you wrote previously.\n",
    "\n",
    "*Note: when you call the `complete_search_table()` function, you should also pass along the `edit_cost` keyword argument, via `complete_search_table(..., edit_cost=edit_cost)`. This ensures that the intended edit cost function is used, and substituting a different function inside `min_edit_distance()` will also cause a different function to be substituted in `complete_search_table()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, edit_cost=lev_edit_cost):\n",
    "    # TODO: complete this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your function works, it should tell you that the minimum edit distance between `\"intention\"` and `\"execution\"` is 8. The code cell below will check this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(min_edit_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.6: a new edit cost function [3 points]\n",
    "\n",
    "In the noisy channel spelling corrector, we generated candidates that were 1 insertion, deletion, substitution, or transposition away from an observed non-word. Ideally, we would like to be able to look at a pair of words and say whether one could be a candidate correction for the other. To do this, we need to know if the edit distance between the words is 1.\n",
    "\n",
    "However, the current edit costs will not suffice for this purpose, for two reasons:  \n",
    "1. we have no way of accounting for transpositions: the edit distance of `caress` and `acress` should be 1, but it is 2, because it is treated as an insertion and a deletion  \n",
    "2. the cost of substitution is too high: the edit distance of `access` and `acress` should be 1, but it is 2  \n",
    "\n",
    "To account for (1), we need to think about what transposition means in this context: it means that the last two characters in the source substring and the last two characters in the target substring are the same, but in reversed order. To assess this possibility in the framework of moving from a previous (source, target) pair to a new (source, target) pair, we will have to consider the case where the source and target both gain *two* characters (not just the *one* we were considering before). Given this consideration, we account for transposition as follows:  \n",
    "- **transposition**: source and target both gain *two* characters; e.g. (*li*, *to*) > (*lisp*, *tops*). The best path from the previous source to previous target can still be used, as long as the gained characters (*sp*, *ps*) are also added to or deleted from the end of the new source and target. Like substitution, it is really a form of multiple-insertion or -deletion, where the characters added and deleted have a particular relation to each other.\n",
    "\n",
    "To account for this addition and (2), we can adopt a different edit cost function, which gives rise to the *Restricted Damerau-Levenshtein* distance.  \n",
    "- **insertion**: costs 1 (no matter what)  \n",
    "- **deletion**: costs 1 (no matter what)  \n",
    "- **substitution**: costs 0 if source and target gain the same single character; otherwise **1**  \n",
    "- **transposition**: costs 1 if the source and target gain the same two characters in opposite orders; otherwise `math.inf` (infinite cost is our representation for the step being disallowed) \n",
    "\n",
    "Complete the function `rdl_edit_cost()` that takes as arguments a previous (source, target) substring pair and a new (source, target) substring pair, identifies the edit associated with the movement from the previous pair to the new pair, and returns the cost of that edit, under the Restricted Damerau-Levenshtein scheme outlined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdl_edit_cost(prev_pair, new_pair):\n",
    "    # TODO: complete this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether your function works as expected, run the following code cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(rdl_edit_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.7: filling in the search table with transpositions [3 points]\n",
    "\n",
    "Incorporating transpositions means that, when filling in the search table, we have to consider the possibility that the shortest distance between the substrings (`source[:i+1]`, `target[:j+1]`), as represented in the cell `table[i][j]`, comes from the substrings and shortes distance corresponding to the cell `table[i-2][j-2]`. This means that a *fourth* possible previous (source, target) step has to be included in the list of options provided to `step_distance()` for consideration.\n",
    "\n",
    "Create a new search table completion function, `complete_search_table_tp()`, which takes as arguments a source string, a target string, and an initialized search table, and returns a completed search table. The only difference between this function and the earlier `complete_search_table()` should be in the number of candidates passed to `step_distance()`.\n",
    "\n",
    "*Note: when in the top row or column of the table, you should not consider transposition, because `table[i-2][j-2]` does not exist. Make sure you have an appropriate if statement to deal with this issue!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_search_table_tp(source, target, table, edit_cost=rdl_edit_cost):\n",
    "    # TODO: complete this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to test your function with `\">lisp\"` as the source and `\">tops\"` as the target. The tester function converts your table into a pandas DataFrame so that it can be read more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(complete_search_table_tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.8: putting it all together (again) [2 points]\n",
    "\n",
    "Complete the function `min_edit_distance_tp()`, which is just like `min_edit_distance()`, except it accounts for the possibility of transposition by using `complete_search_table_tp()` instead of `complete_search_table()`.\n",
    "\n",
    "If your function works, it should tell you that, using the Restricted Damerau-Levenshtein edit cost, the minimum edit distance between `\"intention\"` and `\"execution\"` is 5, and the minimum edit distance between `\"lisp\"` and `\"tops\"` is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance_tp(source, target, edit_cost=rdl_edit_cost):\n",
    "    # TODO: complete this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your function works, it should tell you that the Restricted Damerau-Levenshtein edit distance between `\"lisp\"` and `\"tops\"` is 3. The code cell below will check this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(min_edit_distance_tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a working minimum edit distance algorithm, you can swap out the cost function and compute distances under different assumptions. One reason this is useful is because the cost function can be generated by an error model, by taking the cost of an edit to be the negative log-probability of that edit. The minimum edit distance algorithm with this cost function can then be used to find the most likely sequence of errors that transforms a source string into a target string, together with the probability of this transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Applications and effects of noisy channel models [25 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment, you will write brief responses to questions which direct you to think about applications and effects of language models. You will choose whether your response is based on language technologies (Option A) or language-based research (Option B). **You should only answer questions for a single option; you will not gain extra credit for answering questions for both options. Make sure that you write your chosen option in the designated place at the top of this notebook before you submit the assignment.** \n",
    "\n",
    "You can only choose each option *twice* over the four assignments; before choosing an option, please make sure you have not already chosen it for two other assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will not be grading the quality of your writing, only the quality of your ideas.\n",
    "\n",
    "Regardless of which option you choose, **make sure that you address all parts of each question**. Not answering questions fully is the most common cause of missed points.\n",
    "\n",
    "Your responses do not need to be lengthy; make them only as long as is necessary to convey your ideas. Here are some guidelines:  \n",
    "* *Identify*: 1-2 sentences; give a concrete example of *what* you are identifying  \n",
    "* *Describe*: 1-3 sentences; give specific details about *what* you are describing  \n",
    "* *Explain*: 2-4 sentences; give specific details about *how* something works or *why* a statement holds  \n",
    "\n",
    "When developing your responses, you may find it useful to consult resources such as scholarly publications, news articles, blog posts, etc. (though you are not required to). If you do so, please mention the resources that you consulted, and provide a way in which it can be located (e.g. citation details, a URL, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A: Real-world effects of noisy channel models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you choose this option, you will write brief responses to questions which direct you to consider the potential technological applications of noisy channel models, as well as positive and negative effects these applications can have in the real world. You can consider this a purely hypothetical exercise; you are not required to know whether or how a specific technological application actually uses noisy channel models.  \n",
    "*NB: you should not focus on edit distance or the Viterbi algorithm in this part*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify a potential technological application of noisy channel models. **[3 points]**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One potential technological application is speech recognition. As we discussed in class, speech recognition systems convert spoken language into text. It has been adopted in Zoom and graduation ceremonies to make it easier for the audience to engage with the speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Identify a positive effect that this technological application could have in the real world, and explain why it is a positive effect. **[4 points]**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A positive effect of speech recognition is improved accessibility for individuals with disabilities, particularly those with mobility impairments or visual disabilities. It can also help people who have trouble with following fast speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Explain how noisy channel models contribute to the positive effect. **[4 points]** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noisy channel models enhance speech recognition by effectively handling the uncertainties inherent in speech recognition, such as variations in accents, background noise, and individual speech patterns. These models can better interpret the intended message despite errors in the transmitted audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Describe a potential limitation of the use of noisy channel models in creating this positive effect. **[3 points]**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential limitation is that ASR systems may not perform equally well for all users, particularly for those with strong accents or atypical speech patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Identify a negative effect that this technological application could have in the real world, and explain why it is a negative effect. **[4 points]**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative effect of ASR systems is the potential for miscommunication and inaccurate transcriptions, which can lead to misunderstandings in critical situations. This can be especially problematic if it is related to health or social issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Explain how noisy channel models contribute to the negative effect. **[4 points]**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noisy channel models can misinterpret noisy or ambiguous input due to limitations in their training data and inherent noise in the communication channel. The models might generate incorrect hypotheses about the intended message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Describe a way in which the use of noisy channel models could be improved, to mitigate this negative effect. **[3 points]**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to improve the use of noisy channel models is to incorporate diverse and representative training datasets that include a wide range of accents, dialects, and speech variations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
